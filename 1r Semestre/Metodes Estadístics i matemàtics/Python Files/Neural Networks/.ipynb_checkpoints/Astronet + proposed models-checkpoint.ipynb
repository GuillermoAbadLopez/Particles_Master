{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Astronet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conv. local view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_lv=Input(shape=(201,1))\n",
    "\n",
    "#convolution layer\n",
    "conv1_lv=tf.keras.layers.Conv1D(filters = 16, kernel_size = 5, padding = \"same\", activation = \"relu\")(input_lv)\n",
    "conv2_lv=tf.keras.layers.Conv1D(filters = 16, kernel_size = 5, padding = \"same\", activation = \"relu\")(conv1_lv)\n",
    "\n",
    "#maxpool layer\n",
    "MaxPool1_lv=tf.keras.layers.MaxPooling1D(pool_size = 7, strides = 2)(conv2_lv)\n",
    "\n",
    "#convolution layer\n",
    "conv3_lv=tf.keras.layers.Conv1D(filters = 32, kernel_size = 5, padding = \"same\", activation = \"relu\")(MaxPool1_lv)\n",
    "conv4_lv=tf.keras.layers.Conv1D(filters = 32, kernel_size = 5, padding = \"same\", activation = \"relu\")(conv3_lv)\n",
    "\n",
    "#maxpool layer\n",
    "MaxPool2_lv=tf.keras.layers.MaxPooling1D(pool_size = 7, strides = 2)(conv4_lv)\n",
    "\n",
    "Flatten_lv=tf.keras.layers.Flatten()(MaxPool2_lv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conv. global view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_gv=Input(shape=(2001,1))\n",
    "\n",
    "#convolution layer\n",
    "conv1_gv=tf.keras.layers.Conv1D(filters = 16, kernel_size = 5, padding = \"same\", activation = \"relu\")(input_gv)\n",
    "conv2_gv=tf.keras.layers.Conv1D(filters = 16, kernel_size = 5, padding = \"same\", activation = \"relu\")(conv1_gv)\n",
    "\n",
    "#maxpool layer\n",
    "MaxPool1_gv=tf.keras.layers.MaxPooling1D(pool_size = 5, strides = 2)(conv2_gv)\n",
    "\n",
    "#convolution layer\n",
    "conv3_gv=tf.keras.layers.Conv1D(filters = 32, kernel_size = 5, padding = \"same\", activation = \"relu\")(MaxPool1_gv)\n",
    "conv4_gv=tf.keras.layers.Conv1D(filters = 32, kernel_size = 5, padding = \"same\", activation = \"relu\")(conv3_gv)\n",
    "\n",
    "#maxpool layer\n",
    "MaxPool2_gv=tf.keras.layers.MaxPooling1D(pool_size = 5, strides = 2)(conv4_gv)\n",
    "\n",
    "#convolution layer\n",
    "conv5_gv=tf.keras.layers.Conv1D(filters = 64, kernel_size = 5, padding = \"same\", activation = \"relu\")(MaxPool2_gv)\n",
    "conv6_gv=tf.keras.layers.Conv1D(filters = 64, kernel_size = 5, padding = \"same\", activation = \"relu\")(conv5_gv)\n",
    "\n",
    "#maxpool layer\n",
    "MaxPool3_gv=tf.keras.layers.MaxPooling1D(pool_size = 5, strides = 2)(conv6_gv)\n",
    "\n",
    "#convolution layer\n",
    "conv7_gv=tf.keras.layers.Conv1D(filters = 128, kernel_size = 5, padding = \"same\", activation = \"relu\")(MaxPool3_gv)\n",
    "conv8_gv=tf.keras.layers.Conv1D(filters = 128, kernel_size = 5, padding = \"same\", activation = \"relu\")(conv7_gv)\n",
    "\n",
    "#maxpool layer\n",
    "MaxPool4_gv=tf.keras.layers.MaxPooling1D(pool_size = 5, strides = 2)(conv8_gv)\n",
    "\n",
    "#convolution layer\n",
    "conv9_gv=tf.keras.layers.Conv1D(filters = 256, kernel_size = 5, padding = \"same\", activation = \"relu\")(MaxPool4_gv)\n",
    "conv10_gv=tf.keras.layers.Conv1D(filters = 256, kernel_size = 5, padding = \"same\", activation = \"relu\")(conv9_gv)\n",
    "\n",
    "#maxpool layer\n",
    "MaxPool5_gv=tf.keras.layers.MaxPooling1D(pool_size = 5, strides = 2)(conv10_gv)\n",
    "\n",
    "Flatten_gv=tf.keras.layers.Flatten()(MaxPool5_gv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate local view and global view\n",
    "lv_and_gv=tf.keras.layers.concatenate([Flatten_lv, Flatten_gv],axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Dense1=tf.keras.layers.Dense(512, activation=\"relu\")(lv_and_gv)\n",
    "Dense2=tf.keras.layers.Dense(512, activation=\"relu\")(Dense1)\n",
    "Dense3=tf.keras.layers.Dense(512, activation=\"relu\")(Dense2)\n",
    "Dense4=tf.keras.layers.Dense(512, activation=\"relu\")(Dense3)\n",
    "prediction=tf.keras.layers.Dense(1, activation=\"sigmoid\")(Dense4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Model(inputs=[input_lv,input_gv],outputs=prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### COMPILATION AND TRANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path where the data of accuracy, loss, etc. in each step will be saved\n",
    "name=\"S&B-{}\".format(np.int(time.time()))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\\{}\".format(name), histogram_freq=1)\n",
    "\n",
    "\n",
    "\n",
    "#Adam optimizer with the different parameters\n",
    "adam=tf.keras.optimizers.Adam(learning_rate=1e-05,beta_1=0.9,beta_2=0.999,epsilon=1e-08)\n",
    "\n",
    "#COMPILATION\n",
    "model.compile(optimizer=adam,\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "#training\n",
    "history = model.fit([lv_train_curve, gv_train_curve], \n",
    "                    train_label2, \n",
    "                    batch_size=64, \n",
    "                    epochs=50, \n",
    "                    validation_data=([lv_val_curve,gv_val_curve],val_label2),\n",
    "                    callbacks=[tensorboard_callback]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final configurations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLOBAL & LOCAL VIEW + AUX. PARAMETERS (DEPTH & SNR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HP_shallue_param(convs_gv,convs_lv,denses,units):\n",
    "    '''\n",
    "    Create the structure of a ANN with two different inputs (based of Astronet)\n",
    "    \n",
    "    convs_gv= # of conv. layers in the global view\n",
    "    convs_lv= # of conv. layers in the local view\n",
    "    denses= # of dense layers\n",
    "    units= # of units in the dense layer\n",
    "    \n",
    "    it returns the output layer and the different inputs (only 1 aux. param.)\n",
    "    '''\n",
    "    \n",
    "    input_lv=Input(shape=(201,1))\n",
    "    Input_prev=input_lv\n",
    "    \n",
    "    num_filters=16 #parameter conv. layer\n",
    "\n",
    "    # local view. We want a conf. such as: 2 conv. + Maxpool + ...(repetiton)\n",
    "    for n_c_lv in range(convs_lv):\n",
    "        if n_c_lv%2==0 and n_c_lv!=convs_lv and n_c_lv!=0:\n",
    "            num_filters=num_filters*2 \n",
    "            MaxPool_lv=tf.keras.layers.MaxPooling1D(pool_size = 7, strides = 2)(Input_prev)\n",
    "            conv_lv=tf.keras.layers.Conv1D(filters = num_filters, kernel_size = 5,\n",
    "                                           padding = \"same\", activation = \"relu\")(MaxPool_lv)        \n",
    "            Input_prev=conv_lv\n",
    "        else:\n",
    "            conv_lv=tf.keras.layers.Conv1D(filters = num_filters, kernel_size = 5, \n",
    "                                           padding = \"same\", activation = \"relu\")(Input_prev)\n",
    "            Input_prev=conv_lv\n",
    "    #final MaxPool       \n",
    "    if convs_lv%2==0:\n",
    "        MaxPool_lv=tf.keras.layers.MaxPooling1D(pool_size = 7, strides = 2)(Input_prev)       \n",
    "    Flatten_lv=tf.keras.layers.Flatten()(MaxPool_lv)\n",
    "    \n",
    "\n",
    "    input_gv=Input(shape=(2001,1))\n",
    "    Input_prev=input_gv   \n",
    "    num_filters=16 \n",
    "    \n",
    "    #global view. We want a conf. such as: 2 conv. + Maxpool + ...(repetiton)\n",
    "    for n_c_gv in range(convs_gv):\n",
    "        if n_c_gv%2==0 and n_c_gv!=convs_gv and n_c_gv!=0:\n",
    "            num_filters=num_filters*2 \n",
    "            MaxPool_gv=tf.keras.layers.MaxPooling1D(pool_size = 5, strides = 2)(Input_prev)\n",
    "\n",
    "            conv_gv=tf.keras.layers.Conv1D(filters = num_filters, kernel_size = 5, \n",
    "                                           padding = \"same\", activation = \"relu\")(MaxPool_gv)\n",
    "\n",
    "            Input_prev=conv_gv\n",
    "\n",
    "        else:\n",
    "            conv_gv=tf.keras.layers.Conv1D(filters = num_filters, kernel_size = 5, \n",
    "                                           padding = \"same\", activation = \"relu\")(Input_prev)\n",
    "            Input_prev=conv_gv  \n",
    "    #final MaxPool\n",
    "    if convs_gv%2==0:\n",
    "        MaxPool_gv=tf.keras.layers.MaxPooling1D(pool_size = 5, strides = 2)(Input_prev)\n",
    "    Flatten_gv=tf.keras.layers.Flatten()(MaxPool_gv)\n",
    "    \n",
    "    #aux inputs\n",
    "    aux_input_depth=Input(shape=1)\n",
    "    aux_input_snr=Input(shape=1)    \n",
    "\n",
    "    #concatenate all\n",
    "    lv_and_gv=tf.keras.layers.concatenate([Flatten_lv, Flatten_gv,aux_input_depth,aux_input_snr],axis=-1)\n",
    "    Input_prev=lv_and_gv\n",
    "    \n",
    "    \n",
    "    #fully connected layers\n",
    "    for n_dens in range(denses): \n",
    "        Dense=tf.keras.layers.Dense(units, activation=\"relu\")(Input_prev)\n",
    "        Input_prev=Dense\n",
    "        \n",
    "    if denses==0:\n",
    "        prediction=tf.keras.layers.Dense(1, activation=\"sigmoid\")(Input_prev)\n",
    "    else:\n",
    "        prediction=tf.keras.layers.Dense(1, activation=\"sigmoid\")(Dense)\n",
    "    \n",
    "    return prediction,input_gv,input_lv,aux_input_depth, aux_input_snr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gvconv=10\n",
    "lvconv=4\n",
    "n_dense=4\n",
    "n_units=128\n",
    "\n",
    "#call function\n",
    "pred,gv,lv,depth,snr=HP_shallue_param(gvconv,lvconv,n_dense,n_units)\n",
    "\n",
    "#def inputs and outputs of the model\n",
    "model=Model(inputs=[gv,lv,depth,snr],outputs=pred)\n",
    "\n",
    "#compilation\n",
    "model.compile(optimizer=adam,\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=[\"accuracy\"])\n",
    "\n",
    "#path where the data of accuracy, loss, etc. in each step will be saved\n",
    "name=\"S&V_prova_GV_{}+LV_{}+aux(depth_snr)_ndense-{}_nunit-{}_{}\".format(gvconv,lvconv,n_dense,n_units,np.int(time.time()))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"model_GV_LV_P\\{}\".format(name), histogram_freq=1)\n",
    "\n",
    "#train\n",
    "history = model.fit([gv_train_curve,lv_train_curve,train_TCE_depth,train_model_snr], \n",
    "                    train_label2, \n",
    "                    batch_size=64, \n",
    "                    epochs=50, \n",
    "                    validation_data=([gv_val_curve,lv_val_curve,val_TCE_depth,val_model_snr],val_label2),\n",
    "                    callbacks=[tensorboard_callback]\n",
    "                   )\n",
    "\n",
    "#evaluation and prediction\n",
    "loss, acc = model.evaluate([gv_test_curve,lv_test_curve,test_TCE_depth,test_model_snr],  test_label2, verbose=2)\n",
    "predictions=model.predict([gv_test_curve,lv_test_curve,test_TCE_depth,test_model_snr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GLOBAL & LOCAL VIEW + AUX. PARAMETER (DEPTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HP_shallue_depth(convs_gv,convs_lv,denses,units):\n",
    "    '''\n",
    "    Create the structure of a ANN with two different inputs (based of Astronet)\n",
    "    \n",
    "    convs_gv= # of conv. layers in the global view\n",
    "    convs_lv= # of conv. layers in the local view\n",
    "    denses= # of dense layers\n",
    "    units= # of units in the dense layer\n",
    "    \n",
    "    it returns the output layer and the different inputs (2 aux. param.)\n",
    "    '''\n",
    "    \n",
    "    input_lv=Input(shape=(201,1))\n",
    "    Input_prev=input_lv\n",
    "    num_filters=16\n",
    "\n",
    "    # local view. We want a conf. such as: 2 conv. + Maxpool + ...(repetiton)\n",
    "    for n_c_lv in range(convs_lv):\n",
    "        if n_c_lv%2==0 and n_c_lv!=convs_lv and n_c_lv!=0:\n",
    "           \n",
    "            num_filters=num_filters*2\n",
    "            MaxPool_lv=tf.keras.layers.MaxPooling1D(pool_size = 7, strides = 2)(Input_prev)\n",
    "            conv_lv=tf.keras.layers.Conv1D(filters = num_filters, kernel_size = 5,\n",
    "                                           padding = \"same\", activation = \"relu\")(MaxPool_lv)\n",
    "            \n",
    "            \n",
    "            Input_prev=conv_lv\n",
    "\n",
    "        else:\n",
    "            conv_lv=tf.keras.layers.Conv1D(filters = num_filters, kernel_size = 5, \n",
    "                                           padding = \"same\", activation = \"relu\")(Input_prev)\n",
    "            Input_prev=conv_lv\n",
    "            \n",
    "    #final MaxPool\n",
    "    if convs_lv%2==0:\n",
    "        MaxPool_lv=tf.keras.layers.MaxPooling1D(pool_size = 7, strides = 2)(Input_prev)       \n",
    "    Flatten_lv=tf.keras.layers.Flatten()(MaxPool_lv)\n",
    "    \n",
    "    \n",
    "    input_gv=Input(shape=(2001,1))\n",
    "    Input_prev=input_gv   \n",
    "    num_filters=16\n",
    "    \n",
    "    #global view. We want a conf. such as: 2 conv. + Maxpool + ...(repetiton)\n",
    "    for n_c_gv in range(convs_gv):\n",
    "        if n_c_gv%2==0 and n_c_gv!=convs_gv and n_c_gv!=0:\n",
    "\n",
    "            num_filters=num_filters*2\n",
    "\n",
    "            MaxPool_gv=tf.keras.layers.MaxPooling1D(pool_size = 5, strides = 2)(Input_prev)\n",
    "            conv_gv=tf.keras.layers.Conv1D(filters = num_filters, kernel_size = 5, \n",
    "                                           padding = \"same\", activation = \"relu\")(MaxPool_gv)\n",
    "\n",
    "            Input_prev=conv_gv\n",
    "            \n",
    "\n",
    "        else:\n",
    "\n",
    "            conv_gv=tf.keras.layers.Conv1D(filters = num_filters, kernel_size = 5, \n",
    "                                           padding = \"same\", activation = \"relu\")(Input_prev)\n",
    "            \n",
    "            Input_prev=conv_gv\n",
    "    \n",
    "    #final MaxPool\n",
    "    if convs_gv%2==0:\n",
    "        MaxPool_gv=tf.keras.layers.MaxPooling1D(pool_size = 5, strides = 2)(Input_prev)\n",
    "    Flatten_gv=tf.keras.layers.Flatten()(MaxPool_gv)\n",
    "    \n",
    "    #aux input\n",
    "    aux_input_depth=Input(shape=1)   \n",
    "\n",
    "    #concatenate all\n",
    "    lv_and_gv=tf.keras.layers.concatenate([Flatten_lv, Flatten_gv,aux_input_depth],axis=-1)\n",
    "    Input_prev=lv_and_gv\n",
    "    \n",
    "    #fully connected layers\n",
    "    for n_dens in range(denses): \n",
    "        Dense=tf.keras.layers.Dense(units, activation=\"relu\")(Input_prev)\n",
    "        Input_prev=Dense\n",
    "        \n",
    "    if denses==0:\n",
    "        prediction=tf.keras.layers.Dense(1, activation=\"sigmoid\")(Input_prev)\n",
    "    else:\n",
    "        prediction=tf.keras.layers.Dense(1, activation=\"sigmoid\")(Dense)\n",
    "    \n",
    "    return prediction,input_gv,input_lv,aux_input_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gvconv=10\n",
    "lvconv=4\n",
    "n_dense=6\n",
    "n_units=256\n",
    "\n",
    "#call function\n",
    "pred,gv,lv,depth=HP_shallue_depth(gvconv,lvconv,n_dense,n_units)\n",
    "\n",
    "#def inputs and outputs of the model\n",
    "model=Model(inputs=[gv,lv,depth],outputs=pred)\n",
    "\n",
    "#compilation\n",
    "model.compile(optimizer=adam,\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=[\"accuracy\"])\n",
    "\n",
    "#path where the data of accuracy, loss, etc. in each step will be saved\n",
    "name=\"S&V_prova_GV_{}+LV_{}+aux(depth)_ndense-{}_nunit-{}_{}\".format(gvconv,lvconv,n_dense,n_units,np.int(time.time()))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"model_GV_LV_D\\{}\".format(name), histogram_freq=1)\n",
    "\n",
    "#train\n",
    "history = model.fit([gv_train_curve,lv_train_curve,train_TCE_depth], \n",
    "                    train_label2, \n",
    "                    batch_size=64, \n",
    "                    epochs=50,\n",
    "                    validation_data=([gv_val_curve,lv_val_curve,val_TCE_depth],val_label2),\n",
    "                    callbacks=[tensorboard_callback]\n",
    "                   )\n",
    "\n",
    "#evaluation and prediction\n",
    "loss, acc = model.evaluate([gv_test_curve,lv_test_curve,test_TCE_depth],  test_label2, verbose=2)\n",
    "predictions=model.predict([gv_test_curve,lv_test_curve,test_TCE_depth])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
